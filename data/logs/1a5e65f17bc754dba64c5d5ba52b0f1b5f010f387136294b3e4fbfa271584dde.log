2023-07-01 11:57:54,849 CRIT Supervisor is running as root.  Privileges were not dropped because no user is specified in the config file.  If you intend to run as root, you can set user=root in the config file to avoid this message.
2023-07-01 11:57:54,850 INFO supervisord started with pid 7
2023-07-01 11:57:55,852 INFO spawned: 'nginx' with pid 10
2023-07-01 11:57:55,854 INFO spawned: 'app' with pid 11
2023-07-01 11:57:56,889 INFO success: nginx entered RUNNING state, process has stayed up for > than 1 seconds (startsecs)
2023-07-01 11:57:56,890 INFO success: app entered RUNNING state, process has stayed up for > than 1 seconds (startsecs)
[CTRL] POST /setup
[Time: 01.07.23 11:58:04] [Level: info] id: f4b86666791bd3a7
[Time: 01.07.23 11:58:04] [Level: info] coordinator: True
[Time: 01.07.23 11:58:04] [Level: info] clients: ['585344a35093816f', 'f4b86666791bd3a7']
[Time: 01.07.23 11:58:04] [Level: info] state: initial
[CLIENT] Parsing parameter file...
[API] /setup parsing parameter file 
[API] /setup config file found ... parsing file: /mnt/input/config.yaml
YAML file does not follow specification: missing key: eigenvalues
Setting default: eigenvalues.tsv
YAML file does not follow specification: missing key: explained_variance
Setting default: eigenvalues.tsv
YAML file does not follow specification: missing key: output delimiter
Setting default: tab
[API] /setup config file found ... parsing done
[CLIENT] finished parsing parameter file.
[STARTUP] Instantiate SVD
[Time: 01.07.23 11:58:04] [Level: info] transition: init_pca
[Time: 01.07.23 11:58:05] [Level: info] state: init_pca
[STARTUP] Copy configuration and create dir
/mnt/input/hospital_data_bredel_1.csv
TEST: ['/mnt/input/data_wine_1.csv', '/mnt/input/data_wine_2.csv', '/mnt/input/data_wine_3.csv']
[STARTUP] Configuration copied
Log Transform performed
out {'Row names': array(['fruity', 'woody', 'coffee'], dtype=object), 'Sample count': 3, 'Nans': array([0, 0, 0])}
[Time: 01.07.23 11:58:06] [Level: info] transition: check_row_names
[Time: 01.07.23 11:58:07] [Level: info] state: check_row_names
gathering
[CTRL] POST /data
unifying row names
[{'Row names': array(['fruity', 'woody', 'coffee'], dtype=object), 'Sample count': 3, 'Nans': array([0, 0, 0])}, {'Row names': array(['fruity', 'woody', 'coffee'], dtype=object), 'Sample count': 3, 'Nans': array([0, 0, 0])}]
['fruity', 'woody', 'coffee']
['fruity', 'woody', 'coffee']
[6, 6, 6]
[API] [COORDINATOR] row names identified!
[Time: 01.07.23 11:58:10] [Level: info] transition: wait_for_params
[CTRL] GET /data
[Time: 01.07.23 11:58:11] [Level: info] state: wait_for_params
setting parameters
[API] Setting parameters
['fruity', 'woody', 'coffee']
INDEX
[0, 1, 2]
[Time: 01.07.23 11:58:11] [Level: info] transition: aggregate_sums
[Time: 01.07.23 11:58:12] [Level: info] state: aggregate_sums
[CTRL] POST /data
setting parameters
[{'Sums': array([6.39231742, 5.80735492, 5.5849625 ]), 'Sample count': 3}, {'Sums': array([6.5849625 , 5.9068906 , 6.22881869]), 'Sample count': 3}]
SUMS
[2.16287999 1.95237425 1.96896353]
[Time: 01.07.23 11:58:13] [Level: info] transition: compute_std
[CTRL] GET /data
[Time: 01.07.23 11:58:14] [Level: info] state: compute_std
(3, 1)
[Time: 01.07.23 11:58:14] [Level: info] transition: aggregate_stds
[Time: 01.07.23 11:58:15] [Level: info] state: aggregate_stds
[CTRL] POST /data
setting parameters
[1.94579145 1.64027687 2.14938332]
[1.06128843 1.44375465 0.39662476]
COMPUTE STD
[3.00707988 3.08403153 2.54600807]
STD
[0.77551014 0.78537017 0.71358364]
[2 0]
['coffee' 'fruity']
(array([], dtype=int64),)
[]
[Time: 01.07.23 11:58:16] [Level: info] transition: apply_scaling
[CTRL] GET /data
[Time: 01.07.23 11:58:17] [Level: info] state: apply_scaling
[2 0]
(array([], dtype=int64),)
CURRENT DATA:  <apps.svd.TabData.TabData object at 0x7f54efadb250>
[Time: 01.07.23 11:58:17] [Level: info] transition: mfa_prerequisites
[Time: 01.07.23 11:58:18] [Level: info] state: mfa_prerequisites
Calling start_power_iteration
[Time: 01.07.23 11:58:18] [Level: info] transition: start_power_iteration
[Time: 01.07.23 11:58:19] [Level: info] state: start_power_iteration
[STARTUP] Computing covariance matrix
[STARTUP] Random initialisation
TABDATA SCALED
[[-1.49950327  0.54426434  0.83103354]
 [ 1.088634    0.06064115 -1.21264378]
 [ 1.44487122 -0.53813037 -1.35788361]]
[Time: 01.07.23 11:58:19] [Level: info] transition: aggregate_randomized_projections_cov
[Time: 01.07.23 11:58:20] [Level: info] state: aggregate_randomized_projections_cov
[CTRL] POST /data
3
Global cov
[[ 1.         -0.9230407  -0.9282598 ]
 [-0.9230407   1.          0.89413101]
 [-0.9282598   0.89413101  1.        ]]
resetting k
[Time: 01.07.23 11:58:22] [Level: info] transition: compute_final_h_cov
[CTRL] GET /data
[Time: 01.07.23 11:58:23] [Level: info] state: compute_final_h_cov
Setting k
starting eigenvector norms
2
[Time: 01.07.23 11:58:23] [Level: info] transition: aggregate_local_norm
[Time: 01.07.23 11:58:24] [Level: info] state: aggregate_local_norm
[CTRL] POST /data
[{'Local Eigenvector norm': 9.626454740879916}, {'Local Eigenvector norm': 4.525391084925003}]
[Time: 01.07.23 11:58:25] [Level: info] transition: compute_local_conorm
[CTRL] GET /data
[Time: 01.07.23 11:58:26] [Level: info] state: compute_local_conorm
[Time: 01.07.23 11:58:26] [Level: info] transition: aggregate_local_conorm
[Time: 01.07.23 11:58:27] [Level: info] state: aggregate_local_conorm
[CTRL] POST /data
aggregating co norms
[{'Local Conorms': [0.2698767637489]}, {'Local Conorms': [-0.2698767637489001]}]
[Time: 01.07.23 11:58:28] [Level: info] transition: compute_local_norm
[CTRL] GET /data
[Time: 01.07.23 11:58:29] [Level: info] state: compute_local_norm
starting orthogonalise_current
ending orthogonalise_current
starting eigenvector norms
2
[Time: 01.07.23 11:58:29] [Level: info] transition: aggregate_local_norm
[Time: 01.07.23 11:58:30] [Level: info] state: aggregate_local_norm
[CTRL] POST /data
[{'Local Eigenvector norm': 0.2670862051248467}, {'Local Eigenvector norm': 0.26331493842382325}]
[Time: 01.07.23 11:58:31] [Level: info] transition: normalize_g
[CTRL] GET /data
[Time: 01.07.23 11:58:32] [Level: info] state: normalize_g
Normalising
(3, 2)
2
End normalising
(3, 2)
(2, 2)
(2,)
(3, 2)
[Time: 01.07.23 11:58:32] [Level: info] transition: separate_pca
[Time: 01.07.23 11:58:33] [Level: info] state: separate_pca
[Time: 01.07.23 11:58:33] [Level: info] transition: init_pca
[Time: 01.07.23 11:58:34] [Level: info] state: init_pca
[STARTUP] Copy configuration and create dir
/mnt/input/hospital_data_bredel_1.csv
TEST: ['/mnt/input/data_wine_1.csv', '/mnt/input/data_wine_2.csv', '/mnt/input/data_wine_3.csv']
[STARTUP] Configuration copied
Log Transform performed
out {'Row names': array(['red_fruit', 'roasted', 'vanillin', 'woody_2'], dtype=object), 'Sample count': 3, 'Nans': array([0, 0, 0, 0])}
[Time: 01.07.23 11:58:34] [Level: info] transition: check_row_names
[Time: 01.07.23 11:58:35] [Level: info] state: check_row_names
gathering
[CTRL] POST /data
unifying row names
[{'Row names': array(['red_fruit', 'roasted', 'vanillin', 'woody_2'], dtype=object), 'Sample count': 3, 'Nans': array([0, 0, 0, 0])}, {'Row names': array(['red_fruit', 'roasted', 'vanillin', 'woody_2'], dtype=object), 'Sample count': 3, 'Nans': array([0, 0, 0, 0])}]
['red_fruit', 'roasted', 'vanillin', 'woody_2']
['roasted', 'red_fruit', 'vanillin', 'woody_2']
[6, 6, 6, 6]
[API] [COORDINATOR] row names identified!
[Time: 01.07.23 11:58:37] [Level: info] transition: wait_for_params
[CTRL] GET /data
[Time: 01.07.23 11:58:38] [Level: info] state: wait_for_params
setting parameters
[API] Setting parameters
['roasted', 'red_fruit', 'vanillin', 'woody_2']
INDEX
[1, 0, 2, 3]
[Time: 01.07.23 11:58:38] [Level: info] transition: aggregate_sums
[Time: 01.07.23 11:58:39] [Level: info] state: aggregate_sums
[CTRL] POST /data
setting parameters
[{'Sums': array([6.4918531 , 6.4918531 , 6.32192809, 5.39231742]), 'Sample count': 3}, {'Sums': array([6.7548875 , 7.        , 6.12928302, 6.7548875 ]), 'Sample count': 3}]
SUMS
[2.2077901  2.24864218 2.07520185 2.02453415]
[Time: 01.07.23 11:58:40] [Level: info] transition: compute_std
[CTRL] GET /data
[Time: 01.07.23 11:58:41] [Level: info] state: compute_std
(4, 1)
[Time: 01.07.23 11:58:41] [Level: info] transition: aggregate_stds
[Time: 01.07.23 11:58:42] [Level: info] state: aggregate_stds
[CTRL] POST /data
setting parameters
[0.54320072 0.5589529  2.07218448 1.85570183]
[0.67243226 0.68818444 1.75298098 0.8213831 ]
COMPUTE STD
[1.21563298 1.24713734 3.82516546 2.67708493]
STD
[0.49307869 0.49942714 0.8746617  0.73172193]
[0 1 3]
['roasted' 'red_fruit' 'woody_2']
(array([], dtype=int64),)
[]
[Time: 01.07.23 11:58:43] [Level: info] transition: apply_scaling
[CTRL] GET /data
[Time: 01.07.23 11:58:44] [Level: info] state: apply_scaling
[0 1 3]
(array([], dtype=int64),)
CURRENT DATA:  <apps.svd.TabData.TabData object at 0x7f550f274280>
[Time: 01.07.23 11:58:44] [Level: info] transition: mfa_prerequisites
[Time: 01.07.23 11:58:45] [Level: info] state: mfa_prerequisites
Calling start_power_iteration
[Time: 01.07.23 11:58:45] [Level: info] transition: start_power_iteration
[Time: 01.07.23 11:58:46] [Level: info] state: start_power_iteration
[STARTUP] Computing covariance matrix
[STARTUP] Random initialisation
TABDATA SCALED
[[ 0.76493348  0.23148028 -1.26314037]
 [-1.32888189  0.14673995  0.67341218]
 [ 1.05732096  0.28208191 -1.22927739]
 [ 1.06983368 -0.60073593 -1.40016871]]
[Time: 01.07.23 11:58:46] [Level: info] transition: aggregate_randomized_projections_cov
[Time: 01.07.23 11:58:47] [Level: info] state: aggregate_randomized_projections_cov
[CTRL] POST /data
3
Global cov
[[ 1.         -0.89902451  0.96713063  0.87568938]
 [-0.89902451  1.         -0.91960414 -0.82382266]
 [ 0.96713063 -0.91960414  1.          0.85570599]
 [ 0.87568938 -0.82382266  0.85570599  1.        ]]
[Time: 01.07.23 11:58:49] [Level: info] transition: compute_final_h_cov
[CTRL] GET /data
[Time: 01.07.23 11:58:50] [Level: info] state: compute_final_h_cov
Setting k
starting eigenvector norms
3
[Time: 01.07.23 11:58:50] [Level: info] transition: aggregate_local_norm
[Time: 01.07.23 11:58:51] [Level: info] state: aggregate_local_norm
[CTRL] POST /data
[{'Local Eigenvector norm': 9.65241613687937}, {'Local Eigenvector norm': 8.708671126667}]
[Time: 01.07.23 11:58:52] [Level: info] transition: compute_local_conorm
[CTRL] GET /data
[Time: 01.07.23 11:58:53] [Level: info] state: compute_local_conorm
[Time: 01.07.23 11:58:53] [Level: info] transition: aggregate_local_conorm
[Time: 01.07.23 11:58:54] [Level: info] state: aggregate_local_conorm
[CTRL] POST /data
aggregating co norms
[{'Local Conorms': [-0.2183088987223178]}, {'Local Conorms': [0.21830889872231815]}]
[Time: 01.07.23 11:58:55] [Level: info] transition: compute_local_norm
[CTRL] GET /data
[Time: 01.07.23 11:58:56] [Level: info] state: compute_local_norm
starting orthogonalise_current
ending orthogonalise_current
starting eigenvector norms
3
[Time: 01.07.23 11:58:56] [Level: info] transition: aggregate_local_norm
[Time: 01.07.23 11:58:57] [Level: info] state: aggregate_local_norm
[CTRL] POST /data
[{'Local Eigenvector norm': 0.48060235950336516}, {'Local Eigenvector norm': 0.4750369465723096}]
[Time: 01.07.23 11:58:58] [Level: info] transition: compute_local_conorm
[CTRL] GET /data
[Time: 01.07.23 11:58:59] [Level: info] state: compute_local_conorm
[Time: 01.07.23 11:58:59] [Level: info] transition: aggregate_local_conorm
[Time: 01.07.23 11:59:00] [Level: info] state: aggregate_local_conorm
[CTRL] POST /data
aggregating co norms
[{'Local Conorms': [0.014001542080084663, -0.08102233772145966]}, {'Local Conorms': [-0.014001542080084101, 0.08102233772146948]}]
[Time: 01.07.23 11:59:01] [Level: info] transition: compute_local_norm
[CTRL] GET /data
[Time: 01.07.23 11:59:02] [Level: info] state: compute_local_norm
starting orthogonalise_current
ending orthogonalise_current
starting eigenvector norms
3
[Time: 01.07.23 11:59:02] [Level: info] transition: aggregate_local_norm
[Time: 01.07.23 11:59:03] [Level: info] state: aggregate_local_norm
[CTRL] POST /data
[{'Local Eigenvector norm': 0.4858346948080362}, {'Local Eigenvector norm': 0.04834002498154113}]
[Time: 01.07.23 11:59:04] [Level: info] transition: normalize_g
[CTRL] GET /data
[Time: 01.07.23 11:59:05] [Level: info] state: normalize_g
Normalising
(3, 3)
3
End normalising
(3, 3)
(3, 3)
(3,)
(3, 3)
[Time: 01.07.23 11:59:05] [Level: info] transition: separate_pca
[Time: 01.07.23 11:59:06] [Level: info] state: separate_pca
[Time: 01.07.23 11:59:06] [Level: info] transition: init_pca
[Time: 01.07.23 11:59:07] [Level: info] state: init_pca
[STARTUP] Copy configuration and create dir
/mnt/input/hospital_data_bredel_1.csv
TEST: ['/mnt/input/data_wine_1.csv', '/mnt/input/data_wine_2.csv', '/mnt/input/data_wine_3.csv']
[STARTUP] Configuration copied
Log Transform performed
out {'Row names': array(['fruity_2', 'butter', 'woody_3'], dtype=object), 'Sample count': 3, 'Nans': array([0, 0, 0])}
[Time: 01.07.23 11:59:07] [Level: info] transition: check_row_names
[Time: 01.07.23 11:59:08] [Level: info] state: check_row_names
gathering
[CTRL] POST /data
unifying row names
[{'Row names': array(['fruity_2', 'butter', 'woody_3'], dtype=object), 'Sample count': 3, 'Nans': array([0, 0, 0])}, {'Row names': array(['fruity_2', 'butter', 'woody_3'], dtype=object), 'Sample count': 3, 'Nans': array([0, 0, 0])}]
['fruity_2', 'butter', 'woody_3']
['fruity_2', 'woody_3', 'butter']
[6, 6, 6]
[API] [COORDINATOR] row names identified!
[Time: 01.07.23 11:59:10] [Level: info] transition: wait_for_params
[CTRL] GET /data
[Time: 01.07.23 11:59:11] [Level: info] state: wait_for_params
setting parameters
[API] Setting parameters
['fruity_2', 'woody_3', 'butter']
INDEX
[0, 2, 1]
[Time: 01.07.23 11:59:11] [Level: info] transition: aggregate_sums
[Time: 01.07.23 11:59:12] [Level: info] state: aggregate_sums
[CTRL] POST /data
setting parameters
[{'Sums': array([7.32192809, 6.        , 6.12928302]), 'Sample count': 3}, {'Sums': array([4.169925  , 6.97727992, 7.39231742]), 'Sample count': 3}]
SUMS
[1.91530885 2.16287999 2.25360007]
[Time: 01.07.23 11:59:13] [Level: info] transition: compute_std
[CTRL] GET /data
[Time: 01.07.23 11:59:14] [Level: info] state: compute_std
(3, 1)
[Time: 01.07.23 11:59:14] [Level: info] transition: aggregate_stds
[Time: 01.07.23 11:59:15] [Level: info] state: aggregate_stds
[CTRL] POST /data
setting parameters
[1.34906669 2.07958967 1.88282629]
[1.05604771 0.92749021 1.31083349]
COMPUTE STD
[2.4051144  3.00707988 3.19365978]
STD
[0.69355813 0.77551014 0.79920708]
[0 1]
['fruity_2' 'woody_3']
(array([], dtype=int64),)
[]
[Time: 01.07.23 11:59:16] [Level: info] transition: apply_scaling
[CTRL] GET /data
[Time: 01.07.23 11:59:17] [Level: info] state: apply_scaling
[0 1]
(array([], dtype=int64),)
CURRENT DATA:  <apps.svd.TabData.TabData object at 0x7f54efadb9a0>
[Time: 01.07.23 11:59:17] [Level: info] transition: mfa_prerequisites
[Time: 01.07.23 11:59:18] [Level: info] state: mfa_prerequisites
Calling start_power_iteration
[Time: 01.07.23 11:59:18] [Level: info] transition: start_power_iteration
[Time: 01.07.23 11:59:19] [Level: info] state: start_power_iteration
[STARTUP] Computing covariance matrix
[STARTUP] Random initialisation
TABDATA SCALED
[[ 0.12211111  0.58627998  1.56395131]
 [ 1.07944432 -0.21002947 -1.49950327]
 [ 0.69288031  0.08549477 -1.56855477]]
[Time: 01.07.23 11:59:19] [Level: info] transition: aggregate_randomized_projections_cov
[Time: 01.07.23 11:59:20] [Level: info] state: aggregate_randomized_projections_cov
[CTRL] POST /data
3
Global cov
[[ 1.         -0.61912682 -0.69649453]
 [-0.61912682  1.          0.95791864]
 [-0.69649453  0.95791864  1.        ]]
resetting k
[Time: 01.07.23 11:59:22] [Level: info] transition: compute_final_h_cov
[CTRL] GET /data
[Time: 01.07.23 11:59:23] [Level: info] state: compute_final_h_cov
Setting k
starting eigenvector norms
2
[Time: 01.07.23 11:59:23] [Level: info] transition: aggregate_local_norm
[Time: 01.07.23 11:59:24] [Level: info] state: aggregate_local_norm
[CTRL] POST /data
[{'Local Eigenvector norm': 8.261402397506615}, {'Local Eigenvector norm': 4.3667390723537975}]
[Time: 01.07.23 11:59:25] [Level: info] transition: compute_local_conorm
[CTRL] GET /data
[Time: 01.07.23 11:59:26] [Level: info] state: compute_local_conorm
[Time: 01.07.23 11:59:26] [Level: info] transition: aggregate_local_conorm
[Time: 01.07.23 11:59:27] [Level: info] state: aggregate_local_conorm
[CTRL] POST /data
aggregating co norms
[{'Local Conorms': [-0.02190485000890451]}, {'Local Conorms': [0.021904850008904853]}]
[Time: 01.07.23 11:59:28] [Level: info] transition: compute_local_norm
[CTRL] GET /data
[Time: 01.07.23 11:59:29] [Level: info] state: compute_local_norm
starting orthogonalise_current
ending orthogonalise_current
starting eigenvector norms
2
[Time: 01.07.23 11:59:29] [Level: info] transition: aggregate_local_norm
[Time: 01.07.23 11:59:30] [Level: info] state: aggregate_local_norm
[CTRL] POST /data
[{'Local Eigenvector norm': 0.840709118313968}, {'Local Eigenvector norm': 1.3498905664774647}]
[Time: 01.07.23 11:59:31] [Level: info] transition: normalize_g
[CTRL] GET /data
[Time: 01.07.23 11:59:32] [Level: info] state: normalize_g
Normalising
(3, 2)
2
End normalising
(3, 2)
(2, 2)
(2,)
(3, 2)
[Time: 01.07.23 11:59:32] [Level: info] transition: separate_pca
[Time: 01.07.23 11:59:33] [Level: info] state: separate_pca
Starting scale tabdata
[Time: 01.07.23 11:59:33] [Level: info] transition: scale_tabdata
[Time: 01.07.23 11:59:34] [Level: info] state: scale_tabdata
Starting merge tabdata
[Time: 01.07.23 11:59:34] [Level: info] transition: merging_tabdata
[Time: 01.07.23 11:59:35] [Level: info] state: merging_tabdata
Starting global pca
[Time: 01.07.23 11:59:35] [Level: info] transition: init_pca
[Time: 01.07.23 11:59:36] [Level: info] state: init_pca
[STARTUP] Copy configuration and create dir
/mnt/input/hospital_data_bredel_1.csv
TEST: ['/mnt/input/data_wine_1.csv', '/mnt/input/data_wine_2.csv', '/mnt/input/data_wine_3.csv']
Log Transform performed
out {'Row names': array(['fruity', 'woody', 'coffee', 'roasted', 'red_fruit', 'vanillin',
       'woody_2', 'fruity_2', 'woody_3', 'butter'], dtype=object), 'Sample count': 3, 'Nans': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])}
[Time: 01.07.23 11:59:36] [Level: info] transition: check_row_names
[CTRL] POST /data
[Time: 01.07.23 11:59:37] [Level: info] state: check_row_names
gathering
unifying row names
[{'Row names': array(['fruity', 'woody', 'coffee', 'roasted', 'red_fruit', 'vanillin',
       'woody_2', 'fruity_2', 'woody_3', 'butter'], dtype=object), 'Sample count': 3, 'Nans': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])}, {'Row names': array(['fruity', 'woody', 'coffee', 'roasted', 'red_fruit', 'vanillin',
       'woody_2', 'fruity_2', 'woody_3', 'butter'], dtype=object), 'Sample count': 3, 'Nans': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])}]
['fruity', 'woody', 'coffee', 'roasted', 'red_fruit', 'vanillin', 'woody_2', 'fruity_2', 'woody_3', 'butter']
['red_fruit', 'coffee', 'roasted', 'fruity_2', 'vanillin', 'fruity', 'woody', 'woody_3', 'woody_2', 'butter']
[6, 6, 6, 6, 6, 6, 6, 6, 6, 6]
[API] [COORDINATOR] row names identified!
[Time: 01.07.23 11:59:37] [Level: info] transition: wait_for_params
[CTRL] GET /data
[Time: 01.07.23 11:59:38] [Level: info] state: wait_for_params
setting parameters
[API] Setting parameters
['red_fruit', 'coffee', 'roasted', 'fruity_2', 'vanillin', 'fruity', 'woody', 'woody_3', 'woody_2', 'butter']
INDEX
[4, 2, 3, 7, 5, 0, 1, 8, 6, 9]
[Time: 01.07.23 11:59:38] [Level: info] transition: aggregate_sums
[Time: 01.07.23 11:59:39] [Level: info] state: aggregate_sums
[CTRL] POST /data
setting parameters
[{'Sums': array([-0.97668506, -1.40308646, -0.75260883,  1.35278446, -0.52031074,
       -1.26866805, -0.72872427, -1.80672058, -1.52121028, -2.05856002]), 'Sample count': 3}, {'Sums': array([-0.00570335,  0.18660243, -0.45185842, -2.57772897, -0.62567151,
       -0.22650852, -0.60141028,  0.16710561,  0.41381638,  0.18580577]), 'Sample count': 3}]
SUMS
[-0.1637314  -0.20274734 -0.20074454 -0.20415742 -0.19099704 -0.24919609
 -0.22168909 -0.27326916 -0.18456565 -0.31212571]
[Time: 01.07.23 11:59:40] [Level: info] transition: compute_std
[CTRL] GET /data
[Time: 01.07.23 11:59:41] [Level: info] state: compute_std
(10, 1)
[Time: 01.07.23 11:59:41] [Level: info] transition: aggregate_stds
[Time: 01.07.23 11:59:42] [Level: info] state: aggregate_stds
[CTRL] POST /data
setting parameters
[2.13128906 3.4379803  1.89542063 1.59784258 1.98878656 4.52546733
 2.24409247 4.93393237 2.79600251 5.84149263]
[1.01467294 0.6335832  2.1986069  2.44406639 1.83419946 0.99753289
 2.23475901 1.25361057 0.91205493 1.66554996]
COMPUTE STD
[3.145962   4.0715635  4.09402753 4.04190898 3.82298602 5.52300021
 4.47885147 6.18754293 3.70805744 7.50704259]
STD
[0.79321649 0.90239276 0.90487872 0.89910055 0.87441249 1.05099954
 0.94645142 1.11243363 0.86116868 1.22531976]
[0 8 4 3 1 2 6 5 7]
['red_fruit' 'woody_2' 'vanillin' 'fruity_2' 'coffee' 'roasted' 'woody'
 'fruity' 'woody_3']
(array([], dtype=int64),)
[]
[Time: 01.07.23 11:59:43] [Level: info] transition: apply_scaling
[CTRL] GET /data
[Time: 01.07.23 11:59:44] [Level: info] state: apply_scaling
[0 8 4 3 1 2 6 5 7]
(array([], dtype=int64),)
CURRENT DATA:  <apps.svd.TabData.TabData object at 0x7f54ef9adac0>
[Time: 01.07.23 11:59:44] [Level: info] transition: mfa_prerequisites
[Time: 01.07.23 11:59:45] [Level: info] state: mfa_prerequisites
Calling start_power_iteration
[Time: 01.07.23 11:59:45] [Level: info] transition: start_power_iteration
[Time: 01.07.23 11:59:46] [Level: info] state: start_power_iteration
[STARTUP] Computing covariance matrix
[STARTUP] Random initialisation
TABDATA SCALED
[[-1.66171362  0.33098055  0.71867966]
 [ 1.11473772 -0.29486351 -1.70069294]
 [ 0.72321829  0.39085286 -1.28025387]
 [ 0.32778161  0.66158656  1.19643488]
 [ 0.89921953  0.42920577 -1.26817869]
 [-1.79902197  0.57662232  0.72660518]
 [ 0.91332448  0.28116051 -1.26174359]
 [ 0.83280286  0.09245508 -1.81242375]
 [ 0.91226984 -0.35993602 -1.67582258]
 [ 0.62328667  0.30695311 -1.8460684 ]]
[Time: 01.07.23 11:59:46] [Level: info] transition: aggregate_randomized_projections_cov
[Time: 01.07.23 11:59:47] [Level: info] state: aggregate_randomized_projections_cov
[CTRL] POST /data
3
Global cov
[[ 1.         -0.77432484 -0.79078124  0.16354382 -0.82808028  0.96366251
  -0.84721622 -0.70484694 -0.74147726 -0.63627492]
 [-0.77432484  1.          0.81920885 -0.58745535  0.82332622 -0.77303312
   0.84686719  0.97280373  0.99025666  0.93341934]
 [-0.79078124  0.81920885  1.         -0.42710933  0.98777365 -0.66785165
   0.99245766  0.88306234  0.8396432   0.89400271]
 [ 0.16354382 -0.58745535 -0.42710933  1.         -0.3105805   0.08502732
  -0.37371643 -0.57785066 -0.66013298 -0.61773274]
 [-0.82808028  0.82332622  0.98777365 -0.3105805   1.         -0.73240816
   0.99590445  0.88192445  0.82869762  0.87686598]
 [ 0.96366251 -0.77303312 -0.66785165  0.08502732 -0.73240816  1.
  -0.74907249 -0.67353397 -0.72579521 -0.57255634]
 [-0.84721622  0.84686719  0.99245766 -0.37371643  0.99590445 -0.74907249
   1.          0.89215792  0.85726827  0.8845561 ]
 [-0.70484694  0.97280373  0.88306234 -0.57785066  0.88192445 -0.67353397
   0.89215792  1.          0.97397486  0.9875193 ]
 [-0.74147726  0.99025666  0.8396432  -0.66013298  0.82869762 -0.72579521
   0.85726827  0.97397486  1.          0.94227818]
 [-0.63627492  0.93341934  0.89400271 -0.61773274  0.87686598 -0.57255634
   0.8845561   0.9875193   0.94227818  1.        ]]
[Time: 01.07.23 11:59:49] [Level: info] transition: compute_final_h_cov
[CTRL] GET /data
[Time: 01.07.23 11:59:50] [Level: info] state: compute_final_h_cov
Setting k
starting eigenvector norms
3
[Time: 01.07.23 11:59:50] [Level: info] transition: aggregate_local_norm
[Time: 01.07.23 11:59:51] [Level: info] state: aggregate_local_norm
[CTRL] POST /data
[{'Local Eigenvector norm': 27.375931567327573}, {'Local Eigenvector norm': 12.56741236517842}]
[Time: 01.07.23 11:59:52] [Level: info] transition: compute_local_conorm
[CTRL] GET /data
[Time: 01.07.23 11:59:53] [Level: info] state: compute_local_conorm
[Time: 01.07.23 11:59:53] [Level: info] transition: aggregate_local_conorm
[Time: 01.07.23 11:59:54] [Level: info] state: aggregate_local_conorm
[CTRL] POST /data
aggregating co norms
[{'Local Conorms': [-0.0066116487178414785]}, {'Local Conorms': [0.0066116487178419]}]
[Time: 01.07.23 11:59:55] [Level: info] transition: compute_local_norm
[CTRL] GET /data
[Time: 01.07.23 11:59:56] [Level: info] state: compute_local_norm
starting orthogonalise_current
ending orthogonalise_current
starting eigenvector norms
3
[Time: 01.07.23 11:59:56] [Level: info] transition: aggregate_local_norm
[Time: 01.07.23 11:59:57] [Level: info] state: aggregate_local_norm
[CTRL] POST /data
[{'Local Eigenvector norm': 3.054572103101801}, {'Local Eigenvector norm': 3.293372270919754}]
[Time: 01.07.23 11:59:58] [Level: info] transition: compute_local_conorm
[CTRL] GET /data
[Time: 01.07.23 11:59:59] [Level: info] state: compute_local_conorm
[Time: 01.07.23 11:59:59] [Level: info] transition: aggregate_local_conorm
[Time: 01.07.23 12:00:00] [Level: info] state: aggregate_local_conorm
[CTRL] POST /data
aggregating co norms
[{'Local Conorms': [0.32298921562750194, 0.3292553748888843]}, {'Local Conorms': [-0.3229892156275016, -0.32925537488888196]}]
[Time: 01.07.23 12:00:01] [Level: info] transition: compute_local_norm
[CTRL] GET /data
[Time: 01.07.23 12:00:02] [Level: info] state: compute_local_norm
starting orthogonalise_current
ending orthogonalise_current
starting eigenvector norms
3
[Time: 01.07.23 12:00:02] [Level: info] transition: aggregate_local_norm
[Time: 01.07.23 12:00:03] [Level: info] state: aggregate_local_norm
[CTRL] POST /data
[{'Local Eigenvector norm': 1.9686139173190862}, {'Local Eigenvector norm': 0.5374231469413276}]
[Time: 01.07.23 12:00:04] [Level: info] transition: normalize_g
[CTRL] GET /data
[Time: 01.07.23 12:00:05] [Level: info] state: normalize_g
Normalising
(3, 3)
3
End normalising
(3, 3)
(3, 3)
(3,)
(3, 3)
[Time: 01.07.23 12:00:05] [Level: info] transition: separate_pca
[Time: 01.07.23 12:00:06] [Level: info] state: separate_pca
Starting factor analysis
[Time: 01.07.23 12:00:06] [Level: info] transition: projection_matrix
[Time: 01.07.23 12:00:07] [Level: info] state: projection_matrix
M [[0.1 0.  0.  0.  0.  0.  0.  0.  0.  0. ]
 [0.  0.1 0.  0.  0.  0.  0.  0.  0.  0. ]
 [0.  0.  0.1 0.  0.  0.  0.  0.  0.  0. ]
 [0.  0.  0.  0.1 0.  0.  0.  0.  0.  0. ]
 [0.  0.  0.  0.  0.1 0.  0.  0.  0.  0. ]
 [0.  0.  0.  0.  0.  0.1 0.  0.  0.  0. ]
 [0.  0.  0.  0.  0.  0.  0.1 0.  0.  0. ]
 [0.  0.  0.  0.  0.  0.  0.  0.1 0.  0. ]
 [0.  0.  0.  0.  0.  0.  0.  0.  0.1 0. ]
 [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.1]]
U [[ 0.30009765  0.40335673  0.26863869]
 [-0.33965956  0.10503168 -0.29159055]
 [-0.33396841 -0.04425568  0.42045221]
 [ 0.18233542 -0.70122115  0.26761499]
 [-0.3340651  -0.14849195  0.39627335]
 [ 0.28017363  0.44047841  0.50035931]
 [-0.3399857  -0.11714845  0.31517894]
 [-0.3419617   0.15141082  0.02264127]
 [-0.34037026  0.17191602 -0.23331966]
 [-0.33363891  0.2243364   0.18091409]]
S [2.5139758705610897, 1.5872973021815802, 1.258191863862481]
[Time: 01.07.23 12:00:07] [Level: info] Traceback (most recent call last):
  File "/app/engine/app.py", line 169, in guarded_run
    self.run()
  File "/app/engine/app.py", line 184, in run
    transition = self.current_state.run()
  File "/app/apps/svd/app.py", line 640, in run
    self.projection_matrix()
  File "/app/apps/svd/app.py", line 653, in projection_matrix
    P = np.dot(np.linalg.inv(math.sqrt(M)), np.dot(U, np.linalg.inv(S)))
TypeError: only size-1 arrays can be converted to Python scalars

