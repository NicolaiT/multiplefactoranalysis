2023-07-01 14:10:54,816 CRIT Supervisor is running as root.  Privileges were not dropped because no user is specified in the config file.  If you intend to run as root, you can set user=root in the config file to avoid this message.
2023-07-01 14:10:54,819 INFO supervisord started with pid 7
2023-07-01 14:10:55,822 INFO spawned: 'nginx' with pid 10
2023-07-01 14:10:55,825 INFO spawned: 'app' with pid 11
2023-07-01 14:10:56,862 INFO success: nginx entered RUNNING state, process has stayed up for > than 1 seconds (startsecs)
2023-07-01 14:10:56,862 INFO success: app entered RUNNING state, process has stayed up for > than 1 seconds (startsecs)
[CTRL] POST /setup
[Time: 01.07.23 14:10:58] [Level: info] id: 894db0571df2f45f
[Time: 01.07.23 14:10:58] [Level: info] coordinator: False
[Time: 01.07.23 14:10:58] [Level: info] clients: ['894db0571df2f45f', 'aee5f1823068eebe']
[Time: 01.07.23 14:10:58] [Level: info] state: initial
[CLIENT] Parsing parameter file...
[API] /setup parsing parameter file 
[API] /setup config file found ... parsing file: /mnt/input/config.yaml
YAML file does not follow specification: missing key: eigenvalues
Setting default: eigenvalues.tsv
YAML file does not follow specification: missing key: explained_variance
Setting default: eigenvalues.tsv
YAML file does not follow specification: missing key: output delimiter
Setting default: tab
YAML file does not follow specification: missing key: inertia
Setting default: inertia.tsv
YAML file does not follow specification: missing key: global_factor_score
Setting default: global_factor_score.tsv
YAML file does not follow specification: missing key: omic_factor_score
Setting default: omic_factor_score.tsv
YAML file does not follow specification: missing key: projection_matrix
Setting default: projection_matrix.tsv
[API] /setup config file found ... parsing done
[CLIENT] finished parsing parameter file.
[STARTUP] Instantiate SVD
[Time: 01.07.23 14:10:58] [Level: info] transition: init_pca
[Time: 01.07.23 14:10:59] [Level: info] state: init_pca
[STARTUP] Copy configuration and create dir
/mnt/input/hospital_data_bredel_1.csv
TEST: ['/mnt/input/data_wine_1.csv', '/mnt/input/data_wine_2.csv', '/mnt/input/data_wine_3.csv']
[STARTUP] Configuration copied
Log Transform performed
out {'Row names': array(['fruity', 'woody', 'coffee'], dtype=object), 'Sample count': 3, 'Nans': array([0, 0, 0])}
[Time: 01.07.23 14:10:59] [Level: info] transition: wait_for_params
[Time: 01.07.23 14:11:00] [Level: info] state: wait_for_params
[CTRL] GET /data
[CTRL] POST /data
setting parameters
[API] Setting parameters
['fruity', 'woody', 'coffee']
INDEX
[0, 1, 2]
[Time: 01.07.23 14:11:02] [Level: info] transition: compute_std
[Time: 01.07.23 14:11:03] [Level: info] state: compute_std
[CTRL] GET /data
[CTRL] POST /data
(3, 1)
[Time: 01.07.23 14:11:05] [Level: info] transition: apply_scaling
[Time: 01.07.23 14:11:06] [Level: info] state: apply_scaling
[CTRL] GET /data
[CTRL] POST /data
[2 0]
(array([], dtype=int64),)
CURRENT DATA:  <apps.svd.TabData.TabData object at 0x7f5ca45ec190>
[Time: 01.07.23 14:11:08] [Level: info] transition: mfa_prerequisites
[Time: 01.07.23 14:11:09] [Level: info] state: mfa_prerequisites
Calling start_power_iteration
[Time: 01.07.23 14:11:09] [Level: info] transition: start_power_iteration
[Time: 01.07.23 14:11:10] [Level: info] state: start_power_iteration
[STARTUP] Computing covariance matrix
[STARTUP] Random initialisation
TABDATA SCALED
[[ 1.07944432 -0.74520945 -0.21002947]
 [-1.21264378  0.80546508  0.47054734]
 [-0.53813037  0.49463657  0.49463657]]
[Time: 01.07.23 14:11:10] [Level: info] transition: compute_final_h_cov
[Time: 01.07.23 14:11:11] [Level: info] state: compute_final_h_cov
[CTRL] GET /data
[CTRL] POST /data
Setting k
starting eigenvector norms
2
[Time: 01.07.23 14:11:14] [Level: info] transition: compute_local_conorm
[Time: 01.07.23 14:11:15] [Level: info] state: compute_local_conorm
[CTRL] GET /data
[CTRL] POST /data
[Time: 01.07.23 14:11:17] [Level: info] transition: compute_local_norm
[Time: 01.07.23 14:11:18] [Level: info] state: compute_local_norm
[CTRL] GET /data
[CTRL] POST /data
starting orthogonalise_current
ending orthogonalise_current
starting eigenvector norms
2
[Time: 01.07.23 14:11:20] [Level: info] transition: normalize_g
[Time: 01.07.23 14:11:21] [Level: info] state: normalize_g
[CTRL] GET /data
[CTRL] POST /data
Normalising
(3, 2)
2
End normalising
(3, 2)
(2, 2)
(2,)
(3, 2)
[Time: 01.07.23 14:11:23] [Level: info] transition: separate_pca
[Time: 01.07.23 14:11:24] [Level: info] state: separate_pca
[Time: 01.07.23 14:11:24] [Level: info] transition: init_pca
[Time: 01.07.23 14:11:25] [Level: info] state: init_pca
[STARTUP] Copy configuration and create dir
/mnt/input/hospital_data_bredel_1.csv
TEST: ['/mnt/input/data_wine_1.csv', '/mnt/input/data_wine_2.csv', '/mnt/input/data_wine_3.csv']
[STARTUP] Configuration copied
Log Transform performed
out {'Row names': array(['red_fruit', 'roasted', 'vanillin', 'woody_2'], dtype=object), 'Sample count': 3, 'Nans': array([0, 0, 0, 0])}
[Time: 01.07.23 14:11:25] [Level: info] transition: wait_for_params
[Time: 01.07.23 14:11:26] [Level: info] state: wait_for_params
[CTRL] GET /data
[CTRL] POST /data
setting parameters
[API] Setting parameters
['vanillin', 'woody_2', 'roasted', 'red_fruit']
INDEX
[2, 3, 1, 0]
[Time: 01.07.23 14:11:29] [Level: info] transition: compute_std
[Time: 01.07.23 14:11:30] [Level: info] state: compute_std
[CTRL] GET /data
[CTRL] POST /data
(4, 1)
[Time: 01.07.23 14:11:32] [Level: info] transition: apply_scaling
[Time: 01.07.23 14:11:33] [Level: info] state: apply_scaling
[CTRL] GET /data
[CTRL] POST /data
[2 3 1]
(array([], dtype=int64),)
CURRENT DATA:  <apps.svd.TabData.TabData object at 0x7f5ca45ec340>
[Time: 01.07.23 14:11:35] [Level: info] transition: mfa_prerequisites
[Time: 01.07.23 14:11:36] [Level: info] state: mfa_prerequisites
Calling start_power_iteration
[Time: 01.07.23 14:11:36] [Level: info] transition: start_power_iteration
[Time: 01.07.23 14:11:37] [Level: info] state: start_power_iteration
[STARTUP] Computing covariance matrix
[STARTUP] Random initialisation
TABDATA SCALED
[[-1.22927739  0.83707     0.28208191]
 [-0.60073593  0.76590344  0.76590344]
 [-1.26314037  0.76493348  0.76493348]
 [ 1.5044393  -0.49785477 -0.49785477]]
[Time: 01.07.23 14:11:37] [Level: info] transition: compute_final_h_cov
[Time: 01.07.23 14:11:38] [Level: info] state: compute_final_h_cov
[CTRL] GET /data
[CTRL] POST /data
Setting k
starting eigenvector norms
3
[Time: 01.07.23 14:11:41] [Level: info] transition: compute_local_conorm
[Time: 01.07.23 14:11:42] [Level: info] state: compute_local_conorm
[CTRL] GET /data
[CTRL] POST /data
[Time: 01.07.23 14:11:44] [Level: info] transition: compute_local_norm
[Time: 01.07.23 14:11:45] [Level: info] state: compute_local_norm
[CTRL] GET /data
[CTRL] POST /data
starting orthogonalise_current
ending orthogonalise_current
starting eigenvector norms
3
[Time: 01.07.23 14:11:47] [Level: info] transition: compute_local_conorm
[Time: 01.07.23 14:11:48] [Level: info] state: compute_local_conorm
[CTRL] GET /data
[CTRL] POST /data
[Time: 01.07.23 14:11:50] [Level: info] transition: compute_local_norm
[Time: 01.07.23 14:11:51] [Level: info] state: compute_local_norm
[CTRL] GET /data
[CTRL] POST /data
starting orthogonalise_current
ending orthogonalise_current
starting eigenvector norms
3
[Time: 01.07.23 14:11:53] [Level: info] transition: normalize_g
[Time: 01.07.23 14:11:54] [Level: info] state: normalize_g
[CTRL] GET /data
[CTRL] POST /data
Normalising
(3, 3)
3
End normalising
(3, 3)
(3, 3)
(3,)
(3, 3)
[Time: 01.07.23 14:11:56] [Level: info] transition: separate_pca
[Time: 01.07.23 14:11:57] [Level: info] state: separate_pca
[Time: 01.07.23 14:11:57] [Level: info] transition: init_pca
[Time: 01.07.23 14:11:58] [Level: info] state: init_pca
[STARTUP] Copy configuration and create dir
/mnt/input/hospital_data_bredel_1.csv
TEST: ['/mnt/input/data_wine_1.csv', '/mnt/input/data_wine_2.csv', '/mnt/input/data_wine_3.csv']
[STARTUP] Configuration copied
Log Transform performed
out {'Row names': array(['fruity_2', 'butter', 'woody_3'], dtype=object), 'Sample count': 3, 'Nans': array([0, 0, 0])}
[Time: 01.07.23 14:11:58] [Level: info] transition: wait_for_params
[Time: 01.07.23 14:11:59] [Level: info] state: wait_for_params
[CTRL] GET /data
[CTRL] POST /data
setting parameters
[API] Setting parameters
['fruity_2', 'butter', 'woody_3']
INDEX
[0, 1, 2]
[Time: 01.07.23 14:12:02] [Level: info] transition: compute_std
[Time: 01.07.23 14:12:03] [Level: info] state: compute_std
[CTRL] GET /data
[CTRL] POST /data
(3, 1)
[Time: 01.07.23 14:12:05] [Level: info] transition: apply_scaling
[Time: 01.07.23 14:12:06] [Level: info] state: apply_scaling
[CTRL] GET /data
[CTRL] POST /data
[0 2]
(array([], dtype=int64),)
CURRENT DATA:  <apps.svd.TabData.TabData object at 0x7f5ca44ecc10>
[Time: 01.07.23 14:12:08] [Level: info] transition: mfa_prerequisites
[Time: 01.07.23 14:12:09] [Level: info] state: mfa_prerequisites
Calling start_power_iteration
[Time: 01.07.23 14:12:09] [Level: info] transition: start_power_iteration
[Time: 01.07.23 14:12:10] [Level: info] state: start_power_iteration
[STARTUP] Computing covariance matrix
[STARTUP] Random initialisation
TABDATA SCALED
[[-0.47630665 -0.47630665 -1.3197291 ]
 [-0.83662619  0.69288031  0.93392557]
 [-0.74520945  0.83103354  0.54426434]]
[Time: 01.07.23 14:12:10] [Level: info] transition: compute_final_h_cov
[Time: 01.07.23 14:12:11] [Level: info] state: compute_final_h_cov
[CTRL] GET /data
[CTRL] POST /data
Setting k
starting eigenvector norms
2
[Time: 01.07.23 14:12:14] [Level: info] transition: compute_local_conorm
[Time: 01.07.23 14:12:15] [Level: info] state: compute_local_conorm
[CTRL] GET /data
[CTRL] POST /data
[Time: 01.07.23 14:12:17] [Level: info] transition: compute_local_norm
[Time: 01.07.23 14:12:18] [Level: info] state: compute_local_norm
[CTRL] GET /data
[CTRL] POST /data
starting orthogonalise_current
ending orthogonalise_current
starting eigenvector norms
2
[Time: 01.07.23 14:12:20] [Level: info] transition: normalize_g
[Time: 01.07.23 14:12:21] [Level: info] state: normalize_g
[CTRL] GET /data
[CTRL] POST /data
Normalising
(3, 2)
2
End normalising
(3, 2)
(2, 2)
(2,)
(3, 2)
[Time: 01.07.23 14:12:23] [Level: info] transition: separate_pca
[Time: 01.07.23 14:12:24] [Level: info] state: separate_pca
Starting scale tabdata
[Time: 01.07.23 14:12:24] [Level: info] transition: scale_tabdata
[Time: 01.07.23 14:12:25] [Level: info] state: scale_tabdata
Starting merge tabdata
[Time: 01.07.23 14:12:25] [Level: info] transition: merging_tabdata
[Time: 01.07.23 14:12:26] [Level: info] state: merging_tabdata
Starting global pca
[Time: 01.07.23 14:12:26] [Level: info] transition: init_pca
[Time: 01.07.23 14:12:27] [Level: info] state: init_pca
[STARTUP] Copy configuration and create dir
/mnt/input/hospital_data_bredel_1.csv
TEST: ['/mnt/input/data_wine_1.csv', '/mnt/input/data_wine_2.csv', '/mnt/input/data_wine_3.csv']
Log Transform performed
out {'Row names': array(['fruity', 'woody', 'coffee', 'vanillin', 'woody_2', 'roasted',
       'red_fruit', 'fruity_2', 'butter', 'woody_3'], dtype=object), 'Sample count': 3, 'Nans': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])}
[Time: 01.07.23 14:12:27] [Level: info] transition: wait_for_params
[CTRL] GET /data
[Time: 01.07.23 14:12:28] [Level: info] state: wait_for_params
[CTRL] POST /data
setting parameters
[API] Setting parameters
['vanillin', 'woody_2', 'fruity', 'roasted', 'coffee', 'fruity_2', 'butter', 'woody_3', 'woody', 'red_fruit']
INDEX
[3, 4, 0, 5, 2, 7, 8, 9, 1, 6]
[Time: 01.07.23 14:12:29] [Level: info] transition: compute_std
[Time: 01.07.23 14:12:30] [Level: info] state: compute_std
[CTRL] GET /data
[CTRL] POST /data
(10, 1)
[Time: 01.07.23 14:12:32] [Level: info] transition: apply_scaling
[Time: 01.07.23 14:12:33] [Level: info] state: apply_scaling
[CTRL] GET /data
[CTRL] POST /data
[9 1 0 5 4 3 8 2 7]
(array([], dtype=int64),)
CURRENT DATA:  <apps.svd.TabData.TabData object at 0x7f5ca45eca60>
[Time: 01.07.23 14:12:35] [Level: info] transition: mfa_prerequisites
[Time: 01.07.23 14:12:36] [Level: info] state: mfa_prerequisites
Calling start_power_iteration
[Time: 01.07.23 14:12:36] [Level: info] transition: start_power_iteration
[Time: 01.07.23 14:12:37] [Level: info] state: start_power_iteration
[STARTUP] Computing covariance matrix
[STARTUP] Random initialisation
TABDATA SCALED
[[-1.26817869  0.77872632  0.42920577]
 [-0.35993602  0.74171239  0.74171239]
 [ 0.84447177 -0.42845581  0.07977852]
 [-1.28025387  0.72321829  0.72321829]
 [-0.29486351  0.58784112  0.58784112]
 [-0.2402658  -0.2402658  -1.70527145]
 [-0.43598684  0.62328667  0.72852877]
 [-0.40674389  0.71930767  0.57460204]
 [-1.26174359  0.76367254  0.56532965]
 [ 1.1999393  -0.29394295 -0.29394295]]
[Time: 01.07.23 14:12:37] [Level: info] transition: compute_final_h_cov
[Time: 01.07.23 14:12:38] [Level: info] state: compute_final_h_cov
[CTRL] GET /data
[CTRL] POST /data
Setting k
starting eigenvector norms
3
[Time: 01.07.23 14:12:41] [Level: info] transition: compute_local_conorm
[Time: 01.07.23 14:12:42] [Level: info] state: compute_local_conorm
[CTRL] GET /data
[CTRL] POST /data
[Time: 01.07.23 14:12:44] [Level: info] transition: compute_local_norm
[Time: 01.07.23 14:12:45] [Level: info] state: compute_local_norm
[CTRL] GET /data
[CTRL] POST /data
starting orthogonalise_current
ending orthogonalise_current
starting eigenvector norms
3
[Time: 01.07.23 14:12:47] [Level: info] transition: compute_local_conorm
[Time: 01.07.23 14:12:48] [Level: info] state: compute_local_conorm
[CTRL] GET /data
[CTRL] POST /data
[Time: 01.07.23 14:12:50] [Level: info] transition: compute_local_norm
[Time: 01.07.23 14:12:51] [Level: info] state: compute_local_norm
[CTRL] GET /data
[CTRL] POST /data
starting orthogonalise_current
ending orthogonalise_current
starting eigenvector norms
3
[Time: 01.07.23 14:12:53] [Level: info] transition: normalize_g
[Time: 01.07.23 14:12:54] [Level: info] state: normalize_g
[CTRL] GET /data
[CTRL] POST /data
Normalising
(3, 3)
3
End normalising
(3, 3)
(3, 3)
(3,)
(3, 3)
[Time: 01.07.23 14:12:56] [Level: info] transition: separate_pca
[Time: 01.07.23 14:12:57] [Level: info] state: separate_pca
Starting factor analysis
[Time: 01.07.23 14:12:57] [Level: info] transition: waiting_for_projection_matrix
[Time: 01.07.23 14:12:58] [Level: info] state: waiting_for_projection_matrix
[CTRL] POST /data
[Time: 01.07.23 14:12:59] [Level: info] transition: factor_scores
[Time: 01.07.23 14:13:00] [Level: info] state: factor_scores
P: [[ 0.23016041  0.37141031 -0.38569234  0.          0.          0.
   0.          0.          0.          0.        ]
 [-0.10230631  0.18759389  0.60637094  0.          0.          0.
   0.          0.          0.          0.        ]
 [ 0.27301995 -0.25459724  0.68880412  0.          0.          0.
   0.          0.          0.          0.        ]]
Z [[ 0.55654075 -0.38421568 -0.10828716]
 [-0.62521584  0.41528232  0.24260517]
 [-0.27744968  0.25502511  0.25502511]]
Z [[ 0.55654075 -0.38421568 -0.10828716]
 [-0.62521584  0.41528232  0.24260517]
 [-0.27744968  0.25502511  0.25502511]]
Z [[ 0.55654075 -0.38421568 -0.10828716]
 [-0.62521584  0.41528232  0.24260517]
 [-0.27744968  0.25502511  0.25502511]]
[Time: 01.07.23 14:13:00] [Level: info] transition: waiting_for_global_factor_score
[Time: 01.07.23 14:13:01] [Level: info] state: waiting_for_global_factor_score
[CTRL] POST /data
[Time: 01.07.23 14:13:02] [Level: info] transition: inertia
[Time: 01.07.23 14:13:03] [Level: info] state: inertia
[Time: 01.07.23 14:13:03] [Level: info] transition: mfa_final
[Time: 01.07.23 14:13:04] [Level: info] state: mfa_final
Starting save results
[Time: 01.07.23 14:13:04] [Level: info] transition: save_results
[Time: 01.07.23 14:13:05] [Level: info] state: save_results
SAVING RESULTS
[Time: 01.07.23 14:13:05] [Level: info] Traceback (most recent call last):
  File "/app/engine/app.py", line 169, in guarded_run
    self.run()
  File "/app/engine/app.py", line 184, in run
    transition = self.current_state.run()
  File "/app/apps/svd/app.py", line 783, in run
    self.load('svd').save_MFA(inertia, F, F_omics, P)
  File "/app/apps/svd/FC_Federated_PCA.py", line 226, in save_MFA
    F_omics = pd.DataFrame(F_omics)
  File "/usr/local/lib/python3.8/site-packages/pandas/core/frame.py", line 737, in __init__
    mgr = ndarray_to_mgr(
  File "/usr/local/lib/python3.8/site-packages/pandas/core/internals/construction.py", line 331, in ndarray_to_mgr
    values = _prep_ndarray(values, copy=copy_on_sanitize)
  File "/usr/local/lib/python3.8/site-packages/pandas/core/internals/construction.py", line 591, in _prep_ndarray
    raise ValueError(f"Must pass 2-d input. shape={values.shape}")
ValueError: Must pass 2-d input. shape=(3, 3, 10)

